# -*- coding: utf-8 -*-
"""
í•˜ì´ë¸Œë¦¬ë“œ RAG ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸

1. ì‚¬ìš©ì ì¿¼ë¦¬ ì…ë ¥
2. GPTë¡œ ì¿¼ë¦¬ ë¶„í•´ (filters + semantic_query)
3. Metadata í•„í„°ë§ â†’ respondent_ids
4. Semantic query ì„ë² ë”© â†’ ìœ ì‚¬ ì§ˆë¬¸ ê²€ìƒ‰
5. í•„í„°ë§ëœ ì‚¬ëŒë“¤ì˜ ë‹µë³€ ë²¡í„° ë°˜í™˜
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from parsing import parse_query_with_gpt
from makeSQL import build_metadata_where_clause

import psycopg2
import numpy as np
import torch
from transformers import AutoTokenizer, AutoModel
from dotenv import load_dotenv, find_dotenv
import json

# --- .env íŒŒì¼ ë¡œë“œ ---
load_dotenv(find_dotenv())

# --- ì„¤ì • ---
DB_HOST = os.getenv('DB_HOST', 'localhost')
DB_PORT = os.getenv('DB_PORT', '5432')
DB_NAME = os.getenv('DB_NAME')
DB_USER = os.getenv('DB_USER', 'postgres')
DB_PASSWORD = os.getenv('DB_PASSWORD')

EMBEDDING_DIMENSION = 1024
TOP_K_QUESTIONS = 1  # ê°€ì¥ ìœ ì‚¬í•œ ì§ˆë¬¸ 1ê°œë§Œ (ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ ì œì™¸)

# --- ë°˜í™˜ ë°ì´í„° ìŠ¤í‚¤ë§ˆ ---
RESPONSE_SCHEMA = {
    "type": "object",
    "properties": {
        "answer_data": {
            "type": "array",
            "description": "ê²€ìƒ‰ëœ ë‹µë³€ ë°ì´í„° ë°°ì—´",
            "items": {
                "type": "object",
                "properties": {
                    "answer_id": {"type": "integer", "description": "ë‹µë³€ ê³ ìœ  ID"},
                    "respondent_id": {"type": "string", "description": "ì‘ë‹µì ID (ì˜ˆ: 'w243872155705518')"},
                    "question_id": {"type": "string", "description": "ì§ˆë¬¸ ID (ì˜ˆ: '42', 'w2_Q5')"},
                    "answer_value": {"type": "string", "description": "ì›ë³¸ ë‹µë³€ ê°’ (ì˜ˆ: '1', '2')"},
                    "answer_text": {"type": "string", "description": "ì‚¬ëŒì´ ì½ì„ ìˆ˜ ìˆëŠ” ë‹µë³€ í…ìŠ¤íŠ¸ (ì˜ˆ: 'ì—”ì§€ë‹ˆì–´', 'ì˜ì‚¬')"},
                    "q_title": {"type": "string", "description": "ì§ˆë¬¸ ì œëª© (ì˜ˆ: 'ì „ë¬¸ì§', 'ì§ì—…')"}
                },
                "required": ["answer_id", "respondent_id", "question_id", "answer_value", "answer_text", "q_title"]
            }
        },
        "total_respondents": {
            "type": "integer",
            "description": "ì´ ì‘ë‹µì ìˆ˜ (ì¤‘ë³µ ì œê±°)"
        },
        "total_answers": {
            "type": "integer",
            "description": "ì´ ë‹µë³€ ê°œìˆ˜"
        },
        "unique_respondents_sample": {
            "type": "array",
            "description": "ì‘ë‹µì ID ìƒ˜í”Œ (ìµœëŒ€ 10ê°œ)",
            "items": {"type": "string"}
        }
    },
    "required": ["answer_data", "total_respondents", "total_answers", "unique_respondents_sample"]
}

# --- í—¬í¼ í•¨ìˆ˜ ---
def clean_text_for_embedding(text):
    """í…ìŠ¤íŠ¸ ì •ì œ"""
    if not text:
        return ""
    return str(text).strip()

def mean_pooling(model_output, attention_mask):
    """Mean Pooling"""
    token_embeddings = model_output[0]
    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)
    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)
    return sum_embeddings / sum_mask

# --- KURE ì„ë² ë”© ëª¨ë¸ ---
class KUREEmbeddingModel:
    """KURE ì„ë² ë”© ëª¨ë¸"""
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"[Info] '{self.device}' ë””ë°”ì´ìŠ¤ ì‚¬ìš©")
        
        self.tokenizer = AutoTokenizer.from_pretrained("nlpai-lab/KURE-v1")
        self.model = AutoModel.from_pretrained("nlpai-lab/KURE-v1").to(self.device)
        self.model.eval()
        print("[Info] KURE ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    def embed_query(self, query_text):
        """ë‹¨ì¼ ì¿¼ë¦¬ ì„ë² ë”©"""
        cleaned_text = clean_text_for_embedding(query_text)
        
        encoded_input = self.tokenizer(
            [cleaned_text],
            padding=True,
            truncation=True,
            return_tensors='pt',
            max_length=512
        ).to(self.device)
        
        with torch.no_grad():
            model_output = self.model(**encoded_input)
        
        embedding = mean_pooling(model_output, encoded_input['attention_mask'])
        return embedding.cpu().numpy()[0]

# --- DB ì—°ê²° ---
def connect_to_db():
    """PostgreSQL ì—°ê²°"""
    try:
        conn = psycopg2.connect(
            host=DB_HOST, port=DB_PORT, dbname=DB_NAME,
            user=DB_USER, password=DB_PASSWORD
        )
        return conn
    except Exception as e:
        print(f"[Error] DB ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

# --- Step 1: Metadata í•„í„°ë§ ---
def filter_respondents_by_metadata(conn, filters):
    """Metadata í•„í„°ë¡œ respondent_ids ì¶”ì¶œ"""
    if not filters:
        print("[Step 3] í•„í„° ì—†ìŒ - ì „ì²´ ì‘ë‹µì ëŒ€ìƒ")
        return None
    
    print(f"\n[Step 3] Metadata í•„í„°ë§ ì¤‘... ({len(filters)}ê°œ ì¡°ê±´)")
    
    where_clause, params = build_metadata_where_clause(filters, table_name="metadata")
    
    if not where_clause:
        return None
    
    query = f"SELECT mb_sn FROM metadata {where_clause};"
    
    cur = conn.cursor()
    cur.execute(query, params)
    results = cur.fetchall()
    cur.close()
    
    respondent_ids = [row[0] for row in results]
    print(f"[Result] {len(respondent_ids)}ëª…ì˜ ì‘ë‹µì í•„í„°ë§ ì™„ë£Œ")
    
    return respondent_ids

# --- Step 2: ìœ ì‚¬ ì§ˆë¬¸ ê²€ìƒ‰ ---
def search_similar_questions(conn, query_vector, top_k=TOP_K_QUESTIONS):
    """ì¿¼ë¦¬ ë²¡í„°ì™€ ìœ ì‚¬í•œ ì§ˆë¬¸ ì°¾ê¸°"""
    print(f"\n[Step 2] ìœ ì‚¬í•œ ì§ˆë¬¸ ìƒìœ„ {top_k}ê°œ ê²€ìƒ‰ ì¤‘...")
    
    cur = conn.cursor()
    query = f"""
        SELECT 
            codebook_id,
            codebook_data ->> 'q_title' AS q_title,
            1 - (q_vector <=> %s::vector) AS similarity
        FROM codebooks
        WHERE q_vector IS NOT NULL
        ORDER BY q_vector <=> %s::vector
        LIMIT %s;
    """
    
    vector_list = query_vector.tolist()
    cur.execute(query, (vector_list, vector_list, top_k))
    results = cur.fetchall()
    cur.close()
    
    print(f"[Result] {len(results)}ê°œì˜ ìœ ì‚¬ ì§ˆë¬¸ ë°œê²¬:")
    for codebook_id, q_title, similarity in results:
        print(f"  - [{codebook_id}] {q_title[:50]}... (ìœ ì‚¬ë„: {similarity:.7f})")
    
    return [row[0] for row in results]

# --- Step 3: ë‹µë³€ í†µê³„ ì¡°íšŒ (ìµœì í™”ëœ ì¿¼ë¦¬) ---
def get_answer_statistics(conn, codebook_ids, query_vector, respondent_filter=None):
    """
    ì„ ì •ëœ ì§ˆë¬¸ì— ë‹µë³€í•œ ì‚¬ëŒë“¤ì˜ í†µê³„ ì •ë³´ ë°˜í™˜ (ì¿¼ë¦¬ ìµœì í™”)
    
    ìµœì í™” ì „ëµ:
    1. ë²¡í„° ìœ ì‚¬ë„ë¡œ ê´€ë ¨ ë‹µë³€ ë¨¼ì € í•„í„°ë§ (ì„ íƒë„ ë‚®ìŒ)
    2. ê·¸ ë‹¤ìŒ metadata í•„í„° ì ìš© (ì„ íƒë„ ë†’ìŒ)
    """
    print(f"\n[Step 4] ë‹µë³€ í†µê³„ ì¡°íšŒ ì¤‘ (ìµœì í™”ëœ ì¿¼ë¦¬)...")
    
    cur = conn.cursor()
    vector_list = query_vector.tolist()
    
    if respondent_filter:
        # ìµœì í™”: metadata í•„í„° ë¨¼ì € ì ìš© í›„ ë²¡í„° ìœ ì‚¬ë„ ì •ë ¬
        # 606ëª… â†’ 5ëª…ìœ¼ë¡œ ì¤„ì–´ë“œëŠ” ë¬¸ì œ í•´ê²°
        query = f"""
            SELECT DISTINCT
                a.answer_id,
                a.mb_sn AS respondent_id,
                a.question_id,
                a.answer_value,
                c.codebook_data ->> 'q_title' AS q_title,
                c.codebook_data,
                CASE 
                    WHEN a.a_vector IS NOT NULL THEN a.a_vector <=> %s::vector
                    ELSE 999
                END AS distance
            FROM answers a
            JOIN codebooks c ON a.question_id = c.codebook_id
            WHERE a.question_id = ANY(%s)
              AND a.mb_sn = ANY(%s)
            ORDER BY distance;
        """
        params = (vector_list, codebook_ids, respondent_filter)
    else:
        # metadata í•„í„° ì—†ì´ ë²¡í„° ìœ ì‚¬ë„ë§Œ
        query = f"""
            SELECT DISTINCT
                a.answer_id,
                a.mb_sn AS respondent_id,
                a.question_id,
                a.answer_value,
                c.codebook_data ->> 'q_title' AS q_title,
                c.codebook_data,
                CASE 
                    WHEN a.a_vector IS NOT NULL THEN a.a_vector <=> %s::vector
                    ELSE 999
                END AS distance
            FROM answers a
            JOIN codebooks c ON a.question_id = c.codebook_id
            WHERE a.question_id = ANY(%s)
            ORDER BY distance;
        """
        params = (vector_list, codebook_ids)
    
    cur.execute(query, params)
    results = cur.fetchall()
    cur.close()
    
    print(f"[Result] {len(results)}ê°œì˜ ë‹µë³€ ë°œê²¬")
    
    # ë²¡í„° ìœ ì‚¬ë„ í†µê³„
    with_vector = sum(1 for r in results if r[6] < 999)
    without_vector = len(results) - with_vector
    print(f"  - a_vector ìˆìŒ: {with_vector}ê°œ, ì—†ìŒ: {without_vector}ê°œ")
    
    # ì‘ë‹µì ìˆ˜ ê³„ì‚°
    unique_respondents = set()
    answer_data = []
    
    for row in results:
        answer_id, respondent_id, question_id, answer_value, q_title, codebook_data, distance = row
        
        unique_respondents.add(respondent_id)
        
        # ê°ê´€ì‹ ë‹µë³€ì¸ ê²½ìš° ë³´ê¸° í…ìŠ¤íŠ¸ ë§¤ì¹­
        answer_text = answer_value
        if str(answer_value).isdigit() and codebook_data:
            choices = codebook_data.get('answers', [])
            if choices:  # ê°ê´€ì‹
                for choice in choices:
                    if str(choice.get('qi_val')).strip() == str(answer_value).strip():
                        answer_text = choice.get('qi_title', answer_value)
                        break
            else:  # ìˆ«ìí˜• (ìë…€ìˆ˜ ë“±)
                answer_text = f"{q_title}: {answer_value}"
        
        answer_data.append({
            'answer_id': answer_id,
            'respondent_id': respondent_id,
            'question_id': question_id,
            'answer_value': answer_value,
            'answer_text': answer_text,  # ì‚¬ëŒì´ ì½ì„ ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸
            'q_title': q_title,
            'distance': float(distance) if distance < 999 else None  # ë²¡í„° ìœ ì‚¬ë„ ê±°ë¦¬
        })
    
    print(f"[Result] ì´ {len(unique_respondents)}ëª…ì˜ ì‘ë‹µìê°€ ë‹µë³€í•¨")
    
    # í†µê³„ ê³„ì‚°: ë‹µë³€ë³„ ë¶„í¬
    answer_distribution = {}
    for answer in answer_data:
        answer_text = answer['answer_text']
        if answer_text not in answer_distribution:
            answer_distribution[answer_text] = {
                'count': 0,
                'respondents': set()
            }
        answer_distribution[answer_text]['count'] += 1
        answer_distribution[answer_text]['respondents'].add(answer['respondent_id'])
    
    # ë¹„ìœ¨ ê³„ì‚°
    total_unique = len(unique_respondents)
    statistics = []
    for answer_text, data in answer_distribution.items():
        unique_count = len(data['respondents'])
        percentage = (unique_count / total_unique * 100) if total_unique > 0 else 0
        statistics.append({
            'answer_text': answer_text,
            'count': unique_count,
            'percentage': round(percentage, 2)
        })
    
    # ë¹„ìœ¨ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
    statistics.sort(key=lambda x: x['percentage'], reverse=True)
    
    return {
        'answer_data': answer_data,
        'total_respondents': len(unique_respondents),
        'total_answers': len(results),
        'unique_respondents_sample': list(unique_respondents)[:10],  # ìƒ˜í”Œ 10ëª…ë§Œ
        'statistics': statistics  # ë‹µë³€ë³„ í†µê³„ ì¶”ê°€
    }

# --- ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ ---
def rag_search_pipeline(user_query, top_k=TOP_K_QUESTIONS, use_gpt_parsing=True):
    """
    í•˜ì´ë¸Œë¦¬ë“œ RAG ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸
    
    Args:
        user_query: ì‚¬ìš©ì ìì—°ì–´ ì¿¼ë¦¬
        top_k: ìœ ì‚¬ ì§ˆë¬¸ ìƒìœ„ Kê°œ
        use_gpt_parsing: GPTë¡œ ì¿¼ë¦¬ ë¶„í•´ ì—¬ë¶€ (Falseë©´ ì „ì²´ë¥¼ semantic_queryë¡œ ì‚¬ìš©)
    
    Returns:
        ë‹µë³€ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    print("=" * 70)
    print(f"[User Query] {user_query}")
    print("=" * 70)
    
    # Step 0: ì¿¼ë¦¬ ë¶„í•´
    if use_gpt_parsing:
        print("\n[Step 0] GPTë¡œ ì¿¼ë¦¬ ë¶„í•´ ì¤‘...")
        parsed = parse_query_with_gpt(user_query)
        print(f"[Result] ë¶„í•´ ì™„ë£Œ:")
        print(f"  - Filters: {json.dumps(parsed['filters'], ensure_ascii=False)}")
        print(f"  - Semantic Query: {parsed['semantic_query']}")
        print(f"\n[ìµœì í™”] ì‹¤í–‰ ìˆœì„œ: ì˜ë¯¸ ê²€ìƒ‰(ì„ íƒë„ ë‚®ìŒ) â†’ Metadata í•„í„°(ì„ íƒë„ ë†’ìŒ)")
        
        filters = parsed['filters']
        semantic_query = parsed['semantic_query']
    else:
        print("\n[Step 0] GPT ë¶„í•´ ìŠ¤í‚µ - ì „ì²´ë¥¼ ì˜ë¯¸ ê²€ìƒ‰ì–´ë¡œ ì‚¬ìš©")
        filters = []
        semantic_query = user_query
    
    # ì˜ë¯¸ ê²€ìƒ‰ì–´ê°€ ì—†ìœ¼ë©´ ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©
    if not semantic_query or semantic_query.strip() == "":
        semantic_query = user_query
        print(f"[Warning] ì˜ë¯¸ ê²€ìƒ‰ì–´ê°€ ë¹„ì–´ìˆì–´ ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©: {semantic_query}")
    
    # DB ì—°ê²°
    conn = connect_to_db()
    if not conn:
        return []
    
    try:
        # Step 1: ì˜ë¯¸ ê²€ìƒ‰ì–´ ì„ë² ë”© (ë¨¼ì € ì‹¤í–‰)
        print(f"\n[Step 1] ì˜ë¯¸ ê²€ìƒ‰ì–´ ì„ë² ë”© ì¤‘: '{semantic_query}'")
        model = KUREEmbeddingModel()
        query_vector = model.embed_query(semantic_query)
        print(f"[Result] ì¿¼ë¦¬ ë²¡í„° ìƒì„± ì™„ë£Œ (dim: {len(query_vector)})")
        
        # Step 2: ìœ ì‚¬ ì§ˆë¬¸ ê²€ìƒ‰ (ì„ íƒë„ ë‚®ìŒ - ë¨¼ì € ì‹¤í–‰)
        similar_question_ids = search_similar_questions(conn, query_vector, top_k)
        
        if not similar_question_ids:
            print("[Warning] ìœ ì‚¬í•œ ì§ˆë¬¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return {'answer_data': [], 'total_respondents': 0, 'total_answers': 0, 'unique_respondents': []}
        
        # Step 3: Metadata í•„í„°ë§ (ì„ íƒë„ ë†’ìŒ - ë‚˜ì¤‘ì— ì‹¤í–‰)
        respondent_ids = filter_respondents_by_metadata(conn, filters)
        
        # Step 4: ë‹µë³€ í†µê³„ ì¡°íšŒ (ìµœì í™”ëœ ì¿¼ë¦¬)
        # ë²¡í„° ìœ ì‚¬ë„ë¡œ ë¨¼ì € ì¢íŒ í›„ metadata í•„í„° ì ìš©
        result = get_answer_statistics(conn, similar_question_ids, query_vector, respondent_ids)
        
                # Step 5: ì‘ë‹µìë“¤ì˜ ë‚˜ì´ëŒ€ ë¶„í¬ ì¡°íšŒ
        unique_respondents = list(set([answer['respondent_id'] for answer in result['answer_data']]))
        if unique_respondents:
            cur = conn.cursor()
            cur.execute("""
                SELECT 
                    CASE 
                        WHEN age::integer BETWEEN 20 AND 29 THEN '20ëŒ€'
                        WHEN age::integer BETWEEN 30 AND 39 THEN '30ëŒ€'
                        WHEN age::integer BETWEEN 40 AND 49 THEN '40ëŒ€'
                        WHEN age::integer >= 50 THEN '50ëŒ€'
                        ELSE 'ê¸°íƒ€'
                    END as age_group,
                    COUNT(*) as count
                FROM metadata
                WHERE mb_sn = ANY(%s) AND age IS NOT NULL
                GROUP BY age_group
                ORDER BY age_group
            """, (unique_respondents,))
            
            age_data = cur.fetchall()
            total_count = sum(row[1] for row in age_data if row[0] != 'ê¸°íƒ€')
            
            # í¼ì„¼íŠ¸ ê³„ì‚°
            demographics = {}
            demographics_percent = {}
            for row in age_data:
                if row[0] != 'ê¸°íƒ€':
                    age_group = row[0]
                    count = row[1]
                    percentage = round((count / total_count * 100), 2) if total_count > 0 else 0
                    demographics[age_group] = count
                    demographics_percent[age_group] = percentage
            
            result['demographics'] = demographics
            result['demographics_percent'] = demographics_percent
            print(f"[Step 5] ë‚˜ì´ëŒ€ ë¶„í¬: {demographics} ({demographics_percent})")
            cur.close()
        else:
            result['demographics'] = {}
            result['demographics_percent'] = {}

        # âœ… Step 6: ì§€ì—­ ë¶„í¬ ì¡°íšŒ (í¼ì„¼íŠ¸ê¹Œì§€ ê³„ì‚°)
        if unique_respondents:
            cur = conn.cursor()
            cur.execute("""
                SELECT 
                    region,
                    COUNT(*) AS count
                FROM metadata
                WHERE mb_sn = ANY(%s)
                  AND region IS NOT NULL
                GROUP BY region
                ORDER BY count DESC
            """, (unique_respondents,))
            
            region_rows = cur.fetchall()
            cur.close()

            total_region = sum(row[1] for row in region_rows) if region_rows else 0

            region_distribution = {}
            region_distribution_percent = {}

            for region, count in region_rows:
                region_distribution[region] = count
                if total_region > 0:
                    pct = round(count / total_region * 100, 2)
                else:
                    pct = 0.0
                region_distribution_percent[region] = pct

            result['region_distribution'] = region_distribution
            result['region_distribution_percent'] = region_distribution_percent

            # ğŸ” ë””ë²„ê·¸ ì¶œë ¥ (í¼ì„¼íŠ¸ + ì¸ì›ìˆ˜ í•¨ê»˜)
            print("\n[Step 6] ì§€ì—­ë³„ ì‘ë‹µë¥  ë¹„ì¤‘ (%):")
            for region, count in region_rows:
                pct = region_distribution_percent.get(region, 0.0)
                print(f"  - {region}: {pct}% ({count}ëª…)")
        else:
            result['region_distribution'] = {}
            result['region_distribution_percent'] = {}


        
        print("\n" + "=" * 70)
        print(f"[Complete] ì´ {result['total_respondents']}ëª…ì˜ ì‘ë‹µì, {result['total_answers']}ê°œì˜ ë‹µë³€")
        print("=" * 70)
        
        # ìì—°ì–´ ë‹µë³€ ìƒì„±
        if result['statistics']:
            total_respondents = result['total_respondents']
            answer_summary = f"{total_respondents}ëª…ì˜ ì‘ë‹µì ì¤‘ "
            
            # ìƒìœ„ 3ê°œ
            top_stats = result['statistics'][:3]
            summary_parts = []
            top_count = 0
            
            for stat in top_stats:
                summary_parts.append(f"{stat['answer_text']} {stat['count']}ëª…({stat['percentage']}%)")
                top_count += stat['count']
            
            # ë‚˜ë¨¸ì§€ë¥¼ "ê¸°íƒ€"ë¡œ ë¬¶ê¸°
            if len(result['statistics']) > 3:
                other_count = total_respondents - top_count
                other_percentage = round((other_count / total_respondents * 100), 2) if total_respondents > 0 else 0
                summary_parts.append(f"ê¸°íƒ€ {other_count}ëª…({other_percentage}%)")
            
            answer_summary += ", ".join(summary_parts) + "ì…ë‹ˆë‹¤."
            result['answer_summary'] = answer_summary
            print(f"\n[ë‹µë³€ ìš”ì•½] {answer_summary}")
        
        return result
    
    finally:
        conn.close()
        print("\n[Info] DB ì—°ê²° ì¢…ë£Œ")

# --- ì‹¤í–‰ ì˜ˆì‹œ ---
if __name__ == '__main__':
    # ì˜ˆì‹œ 1: ìì—°ì–´ ì¿¼ë¦¬ (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰)
    query1 = "ì„œìš¸ ê±°ì£¼í•˜ëŠ” 30ëŒ€ ë‚¨ì„±ì˜ ì§ì—… ì¤‘ ì „ë¬¸ì§ì¸ ì‚¬ëŒ"
    results1 = rag_search_pipeline(query1, top_k=1, use_gpt_parsing=True)  # top_k=1ë¡œ ë³€ê²½
    
    print("\n" + "=" * 70)
    print("ì˜ˆì‹œ 2: í•„í„° ì—†ëŠ” ìì—°ì–´ ì¿¼ë¦¬")
    print("=" * 70)
    
    # ì˜ˆì‹œ 2: í•„í„° ì—†ëŠ” ìì—°ì–´ ì¿¼ë¦¬
    query2 = "ì„œìš¸ ê±°ì£¼í•˜ëŠ” 30ëŒ€ ë‚¨ì„±ì˜ ì§ì—… ì¤‘ ì „ë¬¸ì§ì¸ ì‚¬ëŒ"
    results2 = rag_search_pipeline(query2, top_k=1, use_gpt_parsing=True)  # top_k=1ë¡œ ë³€ê²½
    
    print("\n" + "=" * 70)
    print("--- [ê²°ê³¼ 1] ---")
    print("=" * 70)
    if results1 and results1.get('answer_data'):
        # JSON í˜•íƒœë¡œ ì¶œë ¥
        output = {
            "total_respondents": results1['total_respondents'],
            "total_answers": results1['total_answers'],
            "unique_respondents_sample": results1['unique_respondents_sample'],
            "sample_answers": [
                {
                    "respondent_id": answer['respondent_id'],
                    "question_id": answer['question_id'],
                    "q_title": answer['q_title'],
                    "answer_value": answer['answer_value'],
                    "answer_text": answer['answer_text']
                }
                for answer in results1['answer_data'][:5]
            ]
        }
        print(json.dumps(output, ensure_ascii=False, indent=2))
    else:
        print("ê²°ê³¼ ì—†ìŒ")
    
    print("\n" + "=" * 70)
    print("--- [ê²°ê³¼ 2] ---")
    print("=" * 70)
    if results2 and results2.get('answer_data'):
        output = {
            "total_respondents": results2['total_respondents'],
            "total_answers": results2['total_answers'],
            "unique_respondents_sample": results2['unique_respondents_sample']
        }
        print(json.dumps(output, ensure_ascii=False, indent=2))
    else:
        print("ê²°ê³¼ ì—†ìŒ")
    
    # ì˜ˆì‹œ 2: ìˆœìˆ˜ ì˜ë¯¸ ê²€ìƒ‰ (GPT íŒŒì‹± ìŠ¤í‚µ)
    # query2 = "ê²½ì œ ë§Œì¡±ë„"
    # results2 = rag_search_pipeline(query2, top_k=5, use_gpt_parsing=False)
